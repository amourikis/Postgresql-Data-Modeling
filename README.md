# Project summary
This is the first project of Udacitys Data Engineering Nanodegree. For this project, I am working for the startup company which is called Sparkify. On this company they have been collecting data on songs and user acivity with their new music streaming app. The data are on JSON files. A postgres database for storing music and artist records has been created. The data has been extracted from the source, transformed using Pandas DataFrame, and loaded into the database. Two datasets is used in the ETL process. The first dataset is a subset of real data from the Million Song Datasetsong and log data. The second dataset consists of log files in JSON format generated by an event simulator based on the songs in the dataset above.

### Dimension Tables
- users: 
    Contains users in the sparkify app. 

- songs: 
    Contains songs in the database. 

- artists: 
    Contains artists in the database. 
- time: 
    Timestamp of records in `songplays` broken down into specific units.

### Fact Table
- songplays: 
    Records in the log data associated with song plays.

### ETL Pipeline
Transfers data from two local directories (data/song_data, data/log_data) into the tables using SQL and Python.

### Prerequisites
Prerequisites is python 3.x and postgres with a default database named "studentdb" available.

## How to run
1. Run command to install requirements.
    > pip install -r requirements.txt
1. Execute the "create_tables.py" file using terminal.
2. Run Jupiter notebook using terminal.
3. After succesfully open the Jupiter noteboomk,execute the "etl.ipynb" file.
4. Last but not least, execute the "test.ipynb" file.